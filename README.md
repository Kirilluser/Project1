Интеграция и анализ текста: извлечение имен, дат и статистики
Этот проект предназначен для извлечения имен, дат и статистического анализа текста. Он включает в себя две основные функции:

Извлечение имен и фамилий из текста.
Извлечение дат в различных форматах.
Анализ текста: извлечение статистики по словарному составу, подсчет количества строк, слов и символов.

Структура проекта
 Проект состоит из следующих файлов:

    ├── parser_module.py         # Модуль для извлечения имен и дат
    ├── analyzer_module.py       # Модуль для анализа текста
    ├── main.py                  # Основной скрипт для интеграции всех функций
    ├── stopwords.txt            # Файл со стоп-словами для фильтрации
    ├── results/                 # Папка для хранения выходных данных
    │   ├── names.txt            # Файл с уникальными именами
    │   ├── dates.txt            # Файл с уникальными датами
    │   ├── frequent_words.csv   # CSV-файл с частотой слов
    ├── sample.txt               # Пример текстового файла для анализа
    └── README.md                # Этот файл
    
Описание работы

parser_module.py:
Содержит функции для извлечения имен и дат из текста.
Использует регулярные выражения для поиска имен в формате "Имя Фамилия" и дат в двух форматах: "дд.мм.гггг" и "дд месяц гггг".

analyzer_module.py:
   Очищает текст от знаков препинания и стоп-слов.
   Выполняет анализ текста, извлекая частоту слов и сохраняет топ-10 наиболее часто встречающихся слов в CSV файл.
   Также подсчитывает общее количество строк, слов, символов и символов без пробелов.

main.py:
   Читает текст из файла sample.txt, вызывает функции из parser_module.py и analyzer_module.py.
   Формирует отчет в файле report.txt, который содержит статистику по именам, датам, частоте слов, а также общую информацию о тексте.

Установка и запуск
Склонируйте репозиторий или скачайте исходные файлы проекта.
Установите все необходимые зависимости (если они есть):
pip install -r requirements.txt
Подготовьте текстовый файл для анализа, например, sample.txt. В файле должны быть данные, содержащие имена и даты.

Для запуска проекта выполните:
python main.py
После выполнения скрипта будут созданы следующие выходные файлы в папке results:

names.txt — файл с уникальными именами.
dates.txt — файл с уникальными датами.
frequent_words.csv — CSV-файл с топ-10 наиболее часто встречающихся слов.
report.txt — отчет с результатами анализа текста (включая количество строк, слов, символов и т.д.).

Формат входных данных
Входной текст может быть в любом формате, но рекомендуется использовать текстовый файл с расширением .txt, например, sample.txt.
Пример текста:
Петр Иванов 5 января 2023 года был в Москве. Алексей Петров 3 февраля 2021 года приезжал в Санкт-Петербург.
Пример вывода
После выполнения скрипта отчет может выглядеть так:
✔ Найдено имён: 2
✔ Найдено дат: 2
✔ Топ-10 слов: 
 - 5: 1
 - января: 1
 - 2023: 1
 - года: 2
 - Петр: 1
 - Иванов: 1
 - Алексей: 1
 - Петров: 1
 - был: 1
 - Москве: 1
✔ Всего строк: 2
✔ Всего слов: 18
✔ Всего символов: 127
✔ Всего символов без пробелов: 106
Папка results
Все результаты анализа будут сохранены в папке results. Если папка не существует, она будет создана автоматически.

Примечания:
Если файл stopwords.txt не найден, программа продолжит работу без фильтрации стоп-слов.
Вы можете добавить свои собственные стоп-слова в файл stopwords.txt, чтобы улучшить фильтрацию.

## Лицензия

Этот проект лицензирован под [MIT License](LICENSE).

